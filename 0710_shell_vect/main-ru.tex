\documentclass[utf8]{psta}

\subjclass[UDC]{004.42}
\subjclass[BBC]{32.973}
\subjclass[2010]{68N19}

\usepackage{mathtools}
\usepackage{amsfonts}

\title[исследование эффективности векторизации]{Исследование эффективности векторизации гнезд циклов с нерегулярным числом итераций}    

\author{Рыбаков, Алексей Анатольевич}
\address{Межведомственный суперкомпьютерный центр Российской академии наук -- филиал Федерального государственного учреждения <<Федеральный научный центр Научно-исследовательский институт системных исследований Российской академии наук>> (МСЦ РАН -- филиал ФГУ ФНЦ НИИСИ РАН)}
\email{rybakov@jscc.ru}

\info{Рыбаков Алексей Анатольевич -- к ф.-м. н., внс МСЦ РАН --
филиала ФГУ ФНЦ НИИСИ РАН. Области научных интересов
-- математическое моделирование задач газовой динамики с
использованием суперкомпьютеров, методы построения и
управления расчетными сетками, дискретная математика,
теория графов, модели случайных графов, параллельное
программирование, функциональное программирование.}
\image{pics/Rybakov_photo}
\orcid{0000-0002-9755-8830}    

\author{Шумилин, Сергей Сергеевич}
\address{Межведомственный суперкомпьютерный центр Российской академии наук -- филиал Федерального государственного учреждения <<Федеральный научный центр Научно-исследовательский институт системных исследований Российской академии наук>> (МСЦ РАН -- филиал ФГУ ФНЦ НИИСИ РАН)}
\email{shumilin@jscc.ru}
\info{Шумилин Сергей Сергеевич, младший научный сотрудник МСЦ РАН -- филиала ФГУ ФНЦ НИИСИ РАН. Область научных интересов: машинное обучение, анализ данных, алгоритмы, параллельное программирование.}
\image{pics/Shumilin_photo}
\orcid{0000-0002-3953-7054}    

\keywords{векторизация, AVX-512, гнезда циклов с нерегулярным числом итераций, сортировка Шелла, теоретическое ускорение}
\begin{abstract}
Векторизация вычислений является важной низкоуровневой оптимизацией, используемой для создания высокоэффективного параллельного кода.
Особенности набора инструкций AVX-512 позволяют применять векторизацию для сложного программного контекста, в частности для гнезд циклов и циклов с сильно разветвленным управлением.
При использовании векторных инструкций для контекста с неизвестным профилем исполнения существует опасность низкой эффективности векторизации. 
Особенно ярко это проявляется при векторизации гнезд циклов с нерегулярным числом итераций внутреннего цикла.
В статье рассматривается практический подход к векторизации гнезд циклов, основанный на предикатном представлении программы.
В качестве примера приводится реализация сортировки Шелла, компактная реализация которой состоит из гнезда циклов, в котором количество итераций внутреннего цикла носит нерегулярный характер и зависит от номеров итераций внешних циклов.
Такой контекст является крайне неудобным для векторизации.
Приводится сравнение теоретической и практической эффективности векторизации сортировки Шелла, рассматриваются особенности этого программного контекста и объясняется их негативное влияние на проиводительность векторизованного кода.
Полученные результаты могут быть использованы исследователями и разработчиками программного обеспечения для обнаружения причин низкой эффективности векторизации программного кода с похожими особенностями.
\end{abstract}

% Все метаданные должны также присутствовать на английском языке, 

% заключённые в  \selectlanguage{english}...,\selectlanguage{russian}: 

\selectlanguage{english} 
% All the same in English 
\title[Study of the vectorization efficiency]{Study of the vectorization efficiency of loop nests with an irregular number of iterations}
% Last name, coma other names 
\author{Rybakov,A. A.}
% Organisation, where the work done
\address{Joint Supercomputer Center of the Russian Academy of Sciences -- branch of Scientific Research Institute of System Analysis of the Russian Academy of Sciences, Leninsky prospect 32a, Moscow, 119334, Russia}
% author email
\email{rybakov.aax@gmail.com}
% support notes

\author{Shumilin,S. S.}
\email{shumilin@jscc.ru}

% Other information about author only on paper language 
%\info{} %
% author photo
%\image{}
%\orcid{}
% Repeat the same fore each of other authors
%
\begin{abstract}
Computation vectorization is an important low-level optimization used to create highly efficient parallel code.
However, when used in context with an unknown program execution profile, a danger of low effectiveness of the application emerges.
This is especially pronounced when vectorizing nests of cycles with an irregular number of iterations of the inner loop.
The article discusses a comparison of the theoretical and practical efficiency of vectorization on the example of Shell sorting, since this program code is extremely inconvenient for vectorization.
\end{abstract}
\selectlanguage{russian} % Не забывайте отметить возврат на русский язык
% Для локального переключения на другой язык используйте команду 
% \foreignlanguage{english}{Text in English}

\begin{document}           
\maketitle   

\section*{Введение}

В данной статье векторизация рассматривается применительно к набору инструкций AVX-512, представляющему собой 512-битное расширение 256-битных AVX инструкций из набора команд Intel x86 \cite{intel_manual}, поддержанное в семействах микропроцессоров Intel, начиная с Intel Xeon Phi KNL \cite{Jeffers} и Intel Xeon Skylake. 
Данный набор состоит из следующих подмножеств: AVX-512F (Foundation) -- основной набор векторных инструкций с поддержкой маскирования, AVX-512PF (PreFetch) -- инструкции предварительной подкачки данных из памяти, AVX-512ER (Exponential and Reciprocal) -- команды для вычисления экспоненты и обратных значений, AVX-512CD (Conflict Detection) -- инструкции для определения конфликтов, AVX-512BW и AVX-512DQ, поддержанные в Skylake. 
В следующих поколениях процессоров набор инструкций AVX-512 расширяется еще больше, в него входят команды для работы с 52-битными целочисленными значениями, специальные команды для работы с нейросетями и AES шифрованием, реализация арифметики полей Галуа, имплементация специальных битовых операций, а также новый класс комбинированных операций.

Использование масок в векторных операциях, позволяющих осуществлять выборочную обработку отдельных элементов векторов, позволяет реализовать предикатный режим исполнения операций. 
В совокупности с многообразием операций перестановки элементов векторов, комбинированными операциями, операциями множественного доступа в память по произвольным адресам, и многими другими особенностями набора инструкций AVX-512 это позволяет создавать качественный параллельный код, приводящий к кратному ускорению.

Для упрощения векторизации исходного кода для компилятора icc доступны специальные функции-интринсики \cite{compiler_guide, intrinsic_guide}, являющиеся обертками к инструкциям или группам инструкций AVX-512. 
Использование функций-интринсиков и встроенных типов данных для поддержки 512-битных векторов позволяет создавать конкретные векторные инструкции в результирующем коде, оперируя при этом высокоуровневыми сущностями языка программирования C. 
Из множества интринсиков можно выделить следующие группы функций, схожие по структуре. Функции \texttt{swizzle}, \texttt{shuffle}, \texttt{permute} и \texttt{permutevar} осуществляют перестановку элементов вектора и раскрываются в последовательность операций, в которой присутствует операция \texttt{shuf} и пересылка по маске. Для большинства операций AVX"~512 реализованы соответствующие инстринсики, раскрывающиеся в одну конкретную операцию. 
Среди них арифметические операции, побитовые операции, операции чтения из памяти и записи в память, операции конвертации, слияние двух векторов, нахождение обратных значений, получение минимума и максимума из двух значений, операции сравнения, операции с масками, комбинированные операции и другие. 
Некоторые инстринсики, особенно предназначенные для выполнения упакованных трансцендентных операций, раскрываются просто в вызов библиотечной функции (например \texttt{log}, \texttt{hypot}, тригонометрические функции).

Появление набора инструкций AVX-512 вызвало большой интерес со стороны исследователей и разработчиков программного обеспечения, в настоящее время ведутся работы по их использованию для оптимизации приложений из разных научных областей.
Можно отметить, например, работы по векторизации ядра программного кода LAMMPS \cite{McDoniel}, операций с разреженными матрицами \cite{Malas} и матрицами специального вида \cite{Benderskij}.
В работе \cite{Krzikalla} описан подход векторизации гнезда циклов на примере построения множества Мандельброта.
Можно встретить работы, в которых описывается применение векторизации с использованием набора инструкций AVX-512 для других приложений из широкого круга, начиная от задач ядерной физики \cite{Cook}, и численного решения уравнений мелкой воды \cite{Ferreira} и заканчивая задачами дискретной математики, включая векторизацию задач сортировки \cite{Bramas} или генератора псевдослучайных чисел \cite{Guskova}.

Целью данной работы является исследование эффективности векторизации сложных контекстов программы и обнаружение \glqq подводных камней\grqq , приводящих к снижению эффективности векторизованного кода. 
В качестве объекта исследования для данной статьи была выбрана сортировка Шелла, обладающая крайне неудобным контекстом исполнения для векторизации с помощью инструкций AVX-512.

Главным вкладом данной статьи является объяснение объективных причин низкой эффективности векторизации гнезд циклов с нерегулярным количеством итераций внутреннего цикла.
Отсутствие информации о профиле выполнения программы и внешне привлекательная простая реализация может ввести в заблуждение исследователей и разработчиков программного обеспечения, поэтому знание описанной специфики может оказаться полезным при выполнения векторизации программного кода.

В первом разделе приводится краткое описание сортировки Шелла, рассматриваемой в качестве тестового примера.
Во втором разделе описан подход к векторизации гнезда циклов, представляющего ядро сортировки, и объяснены узкие места векторизации данного контекста.
В третьем разделе приводятся формулы вычисления идеального теоретического ускорения от векторизации сортировки Шелла для разных шагов сортировки.
Четвертый раздел содержит описание эксперимента, его результаты и сравнение с теоретическими данными.
В пятом разделе приводится сравнение с близкими работами, в которых также затрагиваются вопросы векторизации циклов с нерегулярным числом итераций.

\section{Описание сортировки Шелла}

Сортировка Шелла \cite{Knuth} представляет собой расширение сортировки вставками, которое работает быстрее, так как позволяет на ранних этапах упорядочить далеко расположенные друг от друга элементы массива, это приводит к тому, что массив становится частично упорядоченным. 
Во время сортировки Шелла выполняется последовательная сортировка подмассивов основного массива, являющихся срезами, при этом шаг среза постоянно уменьшается и на завершающем этапе выполняется обычная сортировка вставками (это соответствует срезу массива с шагом 1).
Выполнение сортировки срезов массива с большими шагами облегчает сортировку срезов с меньшими значениями шага, эффективность сортировки существенно зависит от выбранной последовательности шагов. 

\renewcommand{\arraystretch}{1.8}
\renewcommand{\tabcolsep}{4.0}
\begin{table}[H]
\caption{\label{tab:shell_sequences}Различные последовательности шагов, используемые в сортировке Шелла}
\begin{center}

\begin{tabular}{|c|c|}
\hline
\bf{Последовательность} & \bf{Формула} \\
\hline
Последовательность Шелла, 1959 г. &
$k_1 = \lfloor \frac{N}{2} \rfloor, k_i = \lfloor \frac{k_{i - 1}}{2} \rfloor, k_t = 1$ \\
\hline
Последовательность Хиббарда, 1963 г. &
$2^i - 1 \le N, i \in \mathbb{N}$ \\
\hline
Последовательность Пратта, 1971 г. &
$2^i \cdot 3^j \le \frac{N}{2}, i \in \mathbb{N}, j \in \mathbb{N}$ \\
\hline
Последовательность Седжвика, 1986 г. &
$k_i = 
\begin{cases}
  9 \cdot 2^i - 9 \cdot 2^{\frac{i}{2}} + 1, k \ even\\
  8 \cdot 2^i - 6 \cdot 2^{\frac{i + 1}{2}} + 1, k \ odd
\end{cases}$ \\
\hline
\end{tabular}
\end{center}
\end{table} 

В литературе описано множество существующих последовательностей, из которых мы будем анализировать лишь следующие, представленные в Табл.~\ref{tab:shell_sequences} \cite{Pratt_seq,Hib_seq,Sedjw_seq}:

Каноническая реализация сортировки Шелла состоит из гнезда циклов, содержащего три цикла. 
Внешний цикл выполняется по всем шагам из используемой последовательности шагов, начиная с максимального и заканчивая единицей. 
Два внутренних цикла осуществляют сортировку всех подмассивов, являющихся срезами исходного массива с текущим шагом $k$ (Рис.~\ref{pic:shell_code}).

\begin{figure}
\includegraphics[width=8cm]{pics/pic_shell_code}
\caption{Реализация сортировки Шелла для произвольной последовательности шагов}
\label{pic:shell_code}
\end{figure}

\section{Векторизация сортировки Шелла с помощью инструкций AVX-512}

Рассмотрим возможности по векторизации сортировки Шелла для массива вещественных значений типа \texttt{float} (вектор AVX-512 содержит 16 таких значений). 
Самый вложенный цикл (цикл с счетчиком $j$, будем называть его просто внутренним) выполняет сортировку одного среза, состоящего из элементов массива, с расстоянием $k$ между соседними элементами.
Внутренний цикл не может быть векторизован без выполнения дополнительных модификаций кода, так как между записью элемента $m[j]$ и чтением элемента $m[j - k]$ существует межитерационная зависимость. 
Однако, можно заметить, что две итерации среднего по вложенности цикла (цикла с индуктивной переменной $i$, будем называть его промежуточным) с номерами $i_1$ и $i_2$ не пересекаются по данным и могут быть выполнены параллельно при выполнении условия $|i_1 - i_2| < k$. 
Выполним декомпозицию сортировки Шелла для того, чтобы можно было явно выделить ядро, поддающееся векторизации.

\begin{figure}
\includegraphics[width=10cm]{pics/pic_decomposition}
\caption{Декомпозиция сортировки Шелла для выделения векторизуемых участков кода}
\label{pic:decomposition}
\end{figure}

На Рис.~\ref{pic:decomposition} представлена схема декомпозиции алгоритма сортировки Шелла, в котором явно выделены участки с разной шириной векторизации. 
Сначала выделен блок для шагов $k \ge 16$. 
Для данных значений шагов можно параллельно выполнять 16 соседних итераций промежуточного цикла, при этом достигается максимальная плотность векторизации (показано зеленым цветом на схеме). 
Все итерации промежуточного цикла разбиваются на группы по 16 соседних итераций и остаток, который векторизуется с шириной меньше 16 (показано желтым цветом, а в том случае, когда остаток состоит всего из одной итерации, то векторизация не требуется, что показано красным цветом на схеме). Далее рассматривается блок значений шагов $1 < k < 16$. 
При данных значениях ширина векторизации всегда меньше 16, к тому же, как и в предыдущем блоке, возможно появление невекторизуемого остатка. 
В последнюю очередь рассматривается невекторизуемая финальная сортировка вставками для $k = 1$. 
Наличие участков кода с шириной векторизации менее 16 приводит к неоптимальному результирующему коду, однако есть более опасная причина низкой эффективности векторизации.

\begin{figure}
\includegraphics[width=11cm]{pics/pic_shell_cfg}
\caption{Схема перевода тела внутреннего цикла сортировки Шелла в предикатную форму}
\label{pic:shell_cfg}
\end{figure}

Функция \texttt{shell\_sort\_k\_i\_w}, появившаяся после декомпозиции алгоритма сортировки Шелла, содержит реализацию сортировки $w$ соседних срезов массива, взятых с шагом $k$. 
При этом количество итераций внутреннего цикла данной функции является неизвестным. 
Более того, количество итераций внутреннего цикла при сортировке одного среза никак не связано с количеством итераций внутреннего цикла при сортировке соседнего среза. 
Это является существенной проблемой при попытке объединить код сортировки соседних срезов, используя векторные инструкции. 
Для такого объединения необходимо переписать код сортировки среза в предикатной форме \cite{Volkonskyi}, после чего заменить все инструкции векторными аналогами, а предикаты -- векторными масками (Рис.~\ref{pic:shell_cfg}). 
При этом если до векторизации внутренний цикл завершал работу при обращении предиката в \texttt{false}, то после векторизации внутренний цикл завершит работу, только если все элементы соответствующей векторной маски обнулятся. 
Таким образом, количество итераций векторизованного внутреннего цикла равно максимальному количеству итераций всех объединяемых $w$ циклов. 
Если значения количества итераций соседних объединяемых циклов различаются сильно (а для сортировки Шелла это утверждение верно), то мы получаем потерю эффективности векторизации из за низкой плотности масок векторных инструкций (то есть малый процент элементов векторов на самом деле обрабатывается при выполнении векторной операции).
Такой негативный эффект при векторизации гнезд циклов характерен для дискретных задач, в том числе для задач сортировки, поиска, комбинаторного перебора с отсечением ветвей и т.д.
Для задач численного моделирования физических процессов наоборот данный эффект практически незаметен, профиль исполнения отдельных участков программного кода меняется не сильно при небольших изменениях входных данных.

\begin{figure}
\includegraphics[width=10cm]{pics/pic_shell_code_vect}
\caption{Векторизованный вариант ядра сортировки Шелла}
\label{pic:shell_code_vect}
\end{figure}

Векторизованная версия ядра сортировки Шелла представлена на Рис.~\ref{pic:shell_code_vect}. 
Также стоит обратить внимание на появившуюся в векторном коде операцию \texttt{scatter} (Рис.~\ref{pic:shell_code_vect}, строка 25) множественной записи данных в память с произвольными смещениями относительно базового адреса.
Данная команда появилась как векторный аналог операции записи в память из оригинального кода (Рис.~\ref{pic:shell_code}, строка 23) ввиду той же причины -- нерегулярности количества итераций внутреннего цикла. 
Стоит отметить, что команды \texttt{scatter} являются крайне медленными, что также является причиной снижения эффективности векторизации.

Кроме обозначенной команды \texttt{scatter} в векторизованном коде присутствуют другие команды обращения в память (Рис.~\ref{pic:shell_code_vect}, строки 10, 16, 19). 
Это масочные команды чтения и записи по последовательным адресам, реализованные интринсиками \texttt{\_mm512\_mask\_load\_ps} и \texttt{\_mm512\_mask\_store\_ps}, которые раскрываются в операции невыровненного обращения в память \texttt{vmovups}.
В данном случае нельзя использовать выровненные операции обращения в память, так как в общем случае адреса обращения в данных командах конечно не являются выровненными.
В микропроцессорах Intel Xeon Phi KNL и Intel Xeon Skylake скорость обращения в память команд \texttt{vmovaps} не отличается от скорости обращения \texttt{vmovups} при условии выровненного обращения, поэтому компилятор icc вовсе не генерирует инструкции \texttt{vmovaps} \cite{IntelVMOVUPS}.
Таким образом, при невыполнении условия выровненности адресов вместо аварийного завершения мы получаем снижение производительности программы, однако данное снижение не сравнимо с медленной работой инструкций \texttt{gather} и \texttt{scatter}.

\section{Вычисление теоретического ускорения}

В данном разделе произведем вычисление теоретического ускорения, которое может быть достигнуто при векторизации сортировки Шелла предложенным в этой статье способом. 
При этом под теоретическим ускорением будем подразумевать просто отношение количества итераций внутреннего цикла невекторизованной версии к количеству итераций внутреннего цикла в оптимизированной векторизованной версии кода. Определим данное ускорение более формально.

Сначала рассмотрим невекторизованный код. Обозначим через $T(k, i)$ количество итераций внутреннего цикла при фиксированных $k$ и $i$. 
Тогда не составляет труда вычислить общее количество итераций внутреннего цикла при выполнении сортировки (обозначим эту величину через $T$).

\begin{equation}
T = \sum_{k \in ks}{\sum_{i = k}^{n - 1}{I(k, i)}}
\end{equation}

Теперь рассмотрим векторизованную версию кода. 
Аналогично обозначим через $T_v(k,i)$ количество итераций внутреннего цикла при фиксированных $k$ и $i$. 
Нам известно, что ширина векторизации не может превышать $k$ (из-за зависимостей по обращению к массиву), и 16 (размер вектора), то есть $w(k) = \min(k, 16)$. 
При этом весь диапазон значений $i$ от $k$ до $n - 1$, длина которого равна $n - k$ разбивается на $\lfloor \frac{n - k}{w(k)} \rfloor$ групп по $w$ элементов в каждой, и количество итераций в векторизованном цикле, соответствующем каждой группе равно максимальному значению из количеств итераций невекторизованных циклов, объединяемых в данный векторизованный цикл. 
С учетом векторизации хвостовой части цикла, получим следующую формулу для общего количества итераций векторизованного внутреннего цикла.

\begin{equation}
T_v = \sum_{k \in ks}
{
\left(
\left(
\sum_{g = 0}^{G(k) - 1}{\max_{i = k + w(k)g}^{k + w(k)(g + 1) - 1}{I(k, i)}}
\right)
+ \max_{i = k + w(k)G(k)}^{n - 1}{I(k, i)}
\right)
}
\end{equation}

где $w(k) = \min(k, 16)$, $G(k) = \lfloor \frac{n - k}{w(k)} \rfloor$. 
Значения $T = T(n)$ и $T_v = T_v(n)$ были вычислены при сортировке псевдослучайных массивов с количеством элементов от 10 тыс. до 2 млн. для каждой из последовательностей шагов Хиббарда, Пратта и Сэджвика \cite{Pratt_seq,Hib_seq,Sedjw_seq}. 
На основе этого вычислялось теоретическое ускорение $s(n) = T(n)/T_v(n)$. 
Кроме того, аналогичные характеристики рассчитывались и без учета шага $k = 1$ (данные величины обозначены $T'(n)$, $T'_v(n)$ и $s'(n)$ соответственно). 
Полученные результаты сравнивались с результатами экспериментальных запусков на микропроцессоре Intel Xeon Phi 7290 KNL.

\section{Экспериментальные результаты}
 
Для проведения экспериментов были использованы две версии исходного кода: неоптимизированная функция сортировки и реализованная с помощью функций-инстринсиков.
Обе версии сортировки были собраны компилятором icc с уровнем оптимизаии -O3 и с разрешением генерировать инструкции AVX-512 (\texttt{-xmic-avx512}) для микропроцессора Intel Xeon Phi KNL.
Тестовые запуски и замер времени исполнения выполнялись на одном вычислительном узле суперкомпьютера МВС-10П, на сегменте, базирующимся на микропроцессорах Intel Xeon Phi 7290. 
 
На Рис.~\ref{pic:acc_theor}, Рис.~\ref{pic:acc_exp} представлены результаты теоретических оценок и экспериментальных запусков, исходя из которых получены теоретическое и экспериментальное ускорение сортировки Шелла для последовательностей шагов Шелла, Хиббарда и Сэджвика. 
Из графиков видно, что даже максимальное теоретическое ускорение далеко от идеальной верхней границы (которая равна 16 для значений типа \texttt{float}), достигаемого при векторизации гнезд циклов с регулярным количеством итераций. 
Экспериментальные же результаты ожидаемо оказываются еще ниже, и в конечном итоге финальное ускорение сортировки Шелла редко превышает отметку 2 (что, однако, является неплохим результатом).

Проанализируем гистограммы распределения количества итераций внутреннего цикла для некоторых фиксированных значений $k$. 
Из гистограмм, приведенных на Рис.~\ref{pic:shell_k_4}, Рис.~\ref{pic:shell_k_15}, Рис.~\ref{pic:hibbard_k_3}, Рис.~\ref{pic:hibbard_k_15} видно, что при переходе к векторизованной версии кода меняется характер распределения и количество выполнений внутреннего цикла с малым количеством итераций резко сокращается.

Наличие только одной итерации внутреннего цикла в невекторизованной версии кода означает, что текущий рассматриваемый элемент $m[i]$ уже стоит на своем месте в сортируемом срезе.
Для векторизованной версии одна итерация внутреннего цикла означает, что на своем месте стоят $w$ рассматриваемых элементов $w$ соседних одновременно сортируемых срезов, вероятность чего значительно ниже. 
Таким образом, итерации внутренних циклов с малым количеством итераций растворяются в векторизованном коде, что снижает его производительность.

\begin{figure}
\includegraphics[width=10cm]{pics/theoretical_eff}
\caption{Сравнение теоретического ускорения векторизованной версии сортировки Шелла для различных последовательностей шагов}
\label{pic:acc_theor}
\end{figure}

\begin{figure}
\includegraphics[width=10cm]{pics/experimental_eff}
\caption{Сравнение экспериментального ускорения векторизованной версии сортировки Шелла для различных последовательностей шагов}
\label{pic:acc_exp}
\end{figure}

Теоретическая оценка эффективности векторизации с использованием  последовательности Сэджвика оказалась ближе всего к экспериментальным результатам. Это может быть объяснено тем, что последовательность шагов $ks$ в данном случае достаточно короткая, и сортируемые срезы с разными значениями $k$ слабо коррелируют друг с другом.
В последовательности шагов Сэджвика присутствует только один шаг меньше 16 (это последний шаг $k = 1$), для всех остальных шагов доступно применение векторизации с максимальной плотностью.

\begin{figure}
\includegraphics[width=8cm,height=6cm]{pics/pic_shell_k_4}
\caption{Гистограмма распределения количества итераций внутреннего цикла при сортировке с последовательностью Шелла при $k = 4$}
\label{pic:shell_k_4}
\end{figure}

\begin{figure}
\includegraphics[width=8cm,height=6cm]{pics/pic_shell_k_15}
\caption{Гистограмма распределения количества итераций внутреннего цикла при сортировке с последовательностью Шелла при $k = 15$}
\label{pic:shell_k_15}
\end{figure}

\begin{figure}
\includegraphics[width=8cm,height=6cm]{pics/pic_hibbard_k_3}
\caption{Гистограмма распределения количества итераций внутреннего цикла при сортировке с последовательностью Хиббарда при $k = 3$}
\label{pic:hibbard_k_3}
\end{figure}

\begin{figure}
\includegraphics[width=8cm,height=6cm]{pics/pic_hibbard_k_15}
\caption{Гистограмма распределения количества итераций внутреннего цикла при сортировке с последовательностью Хиббарда при $k = 15$}
\label{pic:hibbard_k_15}
\end{figure}

Противоположностью последовательности Сэджвика является последовательность шагов Пратта, содержащая всевозможные шаги вида $2^i3^j$.
Во-первых, эта последовательность очень длинная и содержит сразу 8 значений, которые меньше максимальной ширины векторизации, что негативно сказывается на производительности.
Во-вторых, срезы, индуцированные такими шагами, являются принципиально сильно коррелирующими, это приводит к нерегулярному снижению количества итераций во внутреннем цикле невекторизованной версии.
В итоге мы имеем очень непостоянный график как теоретического, так и и экспериментального ускорения, с низкой эффективностью векторизации и резкими провалами, опускающимися даже ниже единицы.

\section{Близкие работы}

Во введении к данной работе были упомянуты статьи из разных областей исследований, в которых освещались вопросы векторизации кода с помощью набора инструкций AVX-512.
В данном разделе остановимся только на двух из них, в которых исследуется программный контекст, близкий к нашему.

Условно программный контекст можно разделить на непрерывный и дискретный.
К непрерывному контексту отнесем такой программный код, профиль исполнения которого не сильно меняется при небольших изменениях входных данных.
Для дискретного контекста, наоборот, характерно непредсказуемое изменение профиля исполнения при незначительных изменениях во входных данных.
Задача сортировки является дискретной задачей, именно это отражается в свойстве нерегулярности количества итераций внутреннего цикла.

Из упомянутых работ наиболее близкой к данной является векторизация построения множества Мандельброта, описанная в \cite{Krzikalla}.
Ядро построения множества Мандельброта представляет собой гнездо из двух циклов, в котором количество итераций внутреннего цикла нерегулярно и зависит от номера итерации внешнего цикла.
Хотя тело внутреннего цикла гораздо проще (состоит из одного оператора $z = z * z + c$ и условия выхода), однако основной подход остается тем же -- заменить скалярное представление внутреннего цикла на векторное с использованием масочных инструкций.
Также в задаче построения множества Мандельброта значительно лучше оценка максимального теоретического ускорения (около 15 раз на вещественных данных одинарной точности против показателей 2,5--6 в текущей работе), что приводит к финальному ускорению кода примерно в 6,5 раз без использования дополнительных оптимизаций алгоритма (в текущей работе этот показатель находится на отметке 1,6--2,3).

В работе \cite{Bramas} авторы приводят исследование алгоритмов сортировки с использованием AVX-512 на процессоре Intel KNL.
Они применяют набор инструкций в разных контекстах: новый алгоритм разделения множества, применение битонической сортировки для небольших массивов и предлагают модифицированный вариант быстрой сортировки.
Быстрая сортировка представляет собой двухступенчатый алгоритм, который разделяет исходный массив до тех пор, пока размер подмассивов не станет достаточно малым для использования битонической сортировки.
Реализация гибридного алгоритма сортировки, описанного в \cite{Bramas} изначально предполагает векторное исполнение (особенно в части битонической сортировки коротких массивов), поэтому отсутствует ее сравнение с невекторизованной версией, однако на длинных массивах достигнуто ускорение 1,4 раза по сравнению с реализацией C++ STL.

\section*{Заключение}

На примере сортировки Шелла был рассмотрен крайне неудобный для векторизации контекст исполнения, представленный гнездом циклов с нерегулярным количеством итераций внутреннего цикла.
Даже теоретическое ускорение для такого контекста далеко от идеальной верхней границы, а на практике и вовсе может быть получен негативный эффект от применения векторизации.
Такие свойства характерны прежде всего для дискретных задач, к числу которых относятся задачи сортировки, комбинаторики и перечисления.

Была рассмотрена векторная реализация сортировки Шелла и проанализированы три основные причины ее низкой эффективности.
Основной причиной низкой эффективности векториации гнезда циклов с нерегулярным числом итераций внутреннего цикла является большой разброс количества итераций копий циклов, которые реализуются одновременно с помощью векторных инструкций.
Такой разброс порождает большое количество векторных команд с разреженными масками, что закономерно приводит с снижению производительности.
Другой причиной низкой производительности является наличие в коде межитерационной зависимости по данным, которая ограничивает ширину векторизации при $k < 16$.
Наконец третьей важной причиной является наличие в коде команд множественного обращения в память, которые сильно замедляют скорость работы программы, несмотря на свою гибкость и удобство использования.

Таким образом, полученные результаты говорят о том, что при выполнении векторизации программного кода, который содержит циклы с сильно изменяющимся и нерегулярным количеством итераций, необходимо отдельно оценивать возможность векторизации для избежания неожиданной деградации эффективности программного кода.

Работа выполнена в МСЦ РАН в рамках государственного задания по теме 0065-2019-0016 (reg. no. АААА-А19-119011590098-8). При проведении исследований использовался суперкомпьютер МВС-10П, находящийся в МСЦ РАН.


\begin{thebibliography}{30}

% Начало введения.

\RBibitem{intel_manual}
\by
Intel 64 and IA-32 Architectures Software Developer's Manual. Combined volumes: 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D and 4. Intel Corporation. 2019. URL: https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4 (дата обращения: 21.10.2019)

\Bibitem{Jeffers}
\by J. Jeffers, J. Reinders, A. Sodani 
\book Intel Xeon Phi processor high performance programming
\bookinfo Knights Landing Edition
\edition 2 ed.
\publ Morgan Kaufmann Publ.
\yr 2016
\totalpages 632

\RBibitem{compiler_guide}
\by
Intel C++ Compiler 16.0 User and Reference Guide. Intel Corporation. 2015. URL: https://software.intel.com/en-us/download/intel-c-compiler-160-update-4-user-and-reference-guide (дата обращения: 21.10.2019)

\RBibitem{intrinsic_guide}
\by
Intel Intrinsics Guide. URL: https://software.intel.com/sites/landingpage/ IntrinsicsGuide (дата обращения: 21.10.2019)

% Упоминание близких работ.

\RBibitem{McDoniel}
\by W. McDoniel, M. Hohnerbach, R. Canales. et al.
\paper LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi
\jour J.M. Kunkel et al. (Eds.): ISC High Performance 2017, LNCS
\yr 2017
\vol 10266
\pages 61–-78

\RBibitem{Malas}
\by T. Malas, T. Kurth, J. Deslippe
\paper Optimization of the Sparse Matrix-Vector Products of an IDR Krylov Iterative Solver in EMGeo for the Intel KNL Manycore Processor
\jour M. Taufer et al. (Eds.): ISC High Performance Workshops 2016, LNCS
\yr 2016
\vol 9945
\pages 378--389

\RBibitem{Benderskij}
\by Л. А. Бендерский, А. А. Рыбаков, С. С. Шумилин
\paper Векторизация перемножения малоразмерных матриц специального вида с использованием инструкций AVX-512
\jour Современные информационные технологии и ИТ-образование
\yr 2018
\vol 14
\issue 3
\pages 594--602
\URL http://sitito.cs.msu.ru/index.php/SITITO/article/view/424
\crossref{http://dx.doi.org/10.25559/SITITO.14.201803.594-602}

\RBibitem{Krzikalla}
\by O. Krzikalla, F. Wende, M. Hohnerbach
\paper Dynamic SIMD vector lane scheduling
\jour Lect. Notes Comput. Sci.
\yr 2016
\issue 9945
\pages 354--365

\RBibitem{Cook}
\by B. Cook, P. Maris, M. Shao
\paper High Performance Optimizations for Nuclear Physics Code MFDn on KNL
\jour M. Taufer et al. (Eds.): ISC High Performance Workshops 2016, LNCS
\yr 2016
\vol 9945
\pages 366–-377

\RBibitem{Ferreira}
\by C. R. Ferreira, K. T. Mandli, M. Bader
\paper Vectorization of Riemann solvers for the single- ans multi-layer shallow water equations
\jour Proceedings of the 2018 International Conference on High Performance Computing and Simulation, HPCS 2018
\yr 2018
\pages 415--422

\RBibitem{Bramas}
\by B. Bramas
\paper Fast Sorting Algorithms using AVX-512 on Intel Knights Landing
\jour International Journal of Advanced Computer Science and Applications
\yr 2017
\vol 8
\issue 10
\pages 337--344
\URL https://www.researchgate.net/publication/316542898_Fast_Sorting_Algorithms_using_AVX-512_on_Intel_Knights_Landing

\RBibitem{Guskova}
\by М. С. Гуськова, Л. Ю. Бараш, Л. Н. Щур.
\paper Применение AVX512-векторизации для увеличения производительности генератора псевдослучайных чисел
\jour Труды ИСП РАН
\yr 2018
\vol 30
\issue 1
\pages 115--126

% Сама сортировка.

\RBibitem{Knuth}
\by Д. Кнут
\book Искусство программирования
\bookvol 3
\voltitle Сортировка и поиск
\publ Вильямс
\publaddr М.
\yr 1994
\totalpages 832

\RBibitem{Hib_seq}
\by
A168604, последовательность Хиббарда. URL: https://oeis.org/A168604 (дата обращения 21.10.19)

\RBibitem{Pratt_seq}
\by
A003586, последовательность Пратта. https://oeis.org/A003586 (дата обращения 21.10.19)

\RBibitem{Sedjw_seq}
\by
A033622, последовательность Седжвика. URL: https://oeis.org/A033622 (дата обращения 21.10.19)

% Другое.

\RBibitem{Volkonskyi}
\by В. Ю. Волконский, С. К. Окунев
\paper Предикатное представление как основа оптимизации программы для архитектур с явно выраженной параллельностью
\jour Информационные технологии
\yr 2003
\issue 4
\pages 36--45

\RBibitem{IntelVMOVUPS}
\by
Using Intel AVX without Writing AVX. URL: https://software.intel.com/en-us/articles/using-intel-avx-without-writing-avx (дата обращения: 21.10.2019)

\end{thebibliography}
\end{document}

