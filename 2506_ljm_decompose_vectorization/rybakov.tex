%%
%% ****** ljmsamp.tex 13.06.2018 ******
%%
\documentclass[
11pt,%
tightenlines,%
twoside,%
onecolumn,%
nofloats,%
nobibnotes,%
nofootinbib,%
superscriptaddress,%
noshowpacs,%
centertags]%
{revtex4}
\usepackage{ljm}
\usepackage{listings}
\usepackage{xcolor}

\lstset{
language=C++,
basewidth=0.5em,
xleftmargin=45pt,
xrightmargin=45pt,
basicstyle=\small\ttfamily,
%keywordstyle=\bfseries\underbar,
keywordstyle=\color[rgb]{0,0,1},
numbers=left,
numberstyle=\tiny,
stepnumber=1,
numbersep=10pt,
showspaces=false,
showstringspaces=false,
showtabs=false,
frame=trBL,
tabsize=2,
captionpos=t,
breaklines=true,
breakatwhitespace=false,
escapeinside={\%*}{*)}
}

\begin{document}

\titlerunning{Vectorization} % for running heads
\authorrunning{Rybakov} % for running heads
%\authorrunning{First-Author, Second-Author} % for running heads

\title{Vectorization of the integer calculations \\ in the graph decomposition problem}
% Splitting into lines is performed by the command \\
% The title is written in accordance with the rules of capitalization.

\author{\firstname{A.~A.}~\surname{Rybakov}}
\email[E-mail: ]{rybakov_aa@nrcki.ru,rybakov@jscc.ru,rybakov.aax@gmail.com}
\affiliation{National Research Centre \textquotedblleft Kurchatov Institute\textquotedblright, 123182, Moscow, Academician Kurchatov sq. 1, Russia.}

%\author{\firstname{B.}~\surname{Second-Author}}
%\email[E-mail: ]{Second.Author@email.com}
%\affiliation{Place of work and/or the address of the first and second authors}
%\affiliation{Place of work and/or the address of second authors}
%\noaffiliation % If the author does not specify a place of work.

\firstcollaboration{(Submitted by TODO)} % Add if you know submitter.
%\lastcollaboration{ }

%\received{June 13, 2018} % The date of receipt to the editor, i.e. December 06, 2017

\begin{abstract} % You shouldn't use formulas and citations in the abstract.
The article is devoted to the problem of integer calculations vectorization.
Integer calculations is a program context which mainly works with integers and contains a large number of control transfer operations.
Such a program context is often found in combinatorial optimization problems where one has to work with discrete data structures, memory access indirection, and loop nests with an irregular number of iterations.
These factors negatively affect the use of vectorization, and automatic vectorization is almost impossible for such a context.
The article discusses the possibility of using the AVX-512 instruction set to vectorize code with the listed features, since the advantages of masked vector operations make it possible to achieve acceleration even in the presence of such bottlenecks.
The application of vectorization is considered using the example of a bubble growth algorithm for graph decomposition, where the graph is represented as lists of vertex adjacencies.
For the algorithm under consideration, a method is described for applying vectorization to loop nests using integer masked vector instructions from the AVX-512F set.
The vectorized decomposition algorithm has been tested on graphs with up to 4 million vertices.
Practical results were obtained on an Intel Xeon Phi 7290 Knights Landing microprocessor, and they demonstrated acceleration of the program code in the range of 1.7 -- 2.2 times, depending on the size of the computational mesh.
\end{abstract}

\subclass{68W10, 68R10} % Enter 2010 Mathematics Subject Classification.

\keywords{vectorization, AVX-512, integer calculations, combinatorial optimization, graph decomposition, bubble growth algorithm} % Include keywords separeted by comma.

\maketitle

% Text of article starts here.

\section{Introduction}

High-performance computing makes it possible to simulate natural and technological processes with a high degree of detail, simultaneously take into account many factors of various origins, and quickly analyze numerous options.
This allows us to obtain a picture of the process under study with the required accuracy, reflecting the actual situation as much as possible instead of expensive, dangerous or simply impossible full-scale experiments.
The use of supercomputing technologies can significantly reduce the cost and time required to create new competitive products, facilities, and systems.
The range of high-performance computing applications is very wide.
Thus, using supercomputer modeling, problems of gas dynamics and hydrodynamics \cite{01Smirnov}, molecular dynamics \cite{02Guo}, plasma physics \cite{03Asch}, solid mechanics \cite{04Morgan}, mathematics \cite{05Lohiya} and others are solved.
High-performance computing is used to solve such large computational scientific and technical problems as atmospheric modeling \cite{06Kang}, aircraft design \cite{07Morad}, exploration of oil and gas fields \cite{08Eremin}, modeling of large molecules and polyatomic systems \cite{09Yan} and many others.

When solving a computational problem on a supercomputer system, parallelization must be performed between its nodes to speed up calculations \cite{10Voevodin}.
The next level of computing parallelization is parallelization within a single computing node on shared memory \cite{11Zhou}.
The lowest level of parallelization of calculations can be considered vectorization – parallelization at the level of individual instructions \cite{12Feng}.

Vectorization is an important low-level optimization of software code, which can be used to achieve multiple acceleration of supercomputer applications.
All major modern microprocessor architectures (x86, ARM, Power, <<Elbrus>>, LoongArch, Sunway, and others) support vector computing, and there is a tendency to increase the size of the vector (today the maximum length is 512 bits, but now this length is logically unlimited, given the sets of vector instructions with a variable the length
of the vector).

Currently, the most advantageous set of vector instructions is the AVX-512 set, as it supports the possibility of selective processing of vector elements using vector masks.
This unique feature allows you to vectorize a complex programming context containing control transfer commands, loop nests, and function calls.
It can be considered that for the first time the AVX-512 vector instruction set was supported in 2016 in Intel Xeon Phi Knights Landing (KNL) microprocessors, since the earlier generation Intel Xeon Phi Knights Corner (KNC) is an accelerator, and the vector code for it is not x86 compatible.
Since that moment, the issues of application vectorization have been actively discussed in the scientific community.
There are many papers on the vectorization of the software contest in application to various subject areas: gas dynamic solvers \cite{12-1Kulikov}, encryption tools \cite{12-2Buhrow}, time series analysis \cite{12-3Quislant}, sorting of an array of numbers \cite{12-4Blacher}, fast Fourier transform \cite{12-5Sansone} and more.

In this paper, we will consider the application of vectorization using the AVX-512 instruction set to an integer calculations containing loops with an irregular number of iterations.
As such, we will take the bubble growth algorithm of graph decomposition, in which a simultaneous breadth-first traversal of the graph is performed from randomly located initiating vertices.

\section{Bubble growth graph decomposition algorithm}

Currently, there is a wide variety of graph decomposition algorithms that are applied depending on the size of the graph being processed and the requirements for the quality of decomposition \cite{13Ayall}.
At the same time, the size requirements of the processed graphs are constantly increasing, and today the decomposition problem is considered for graphs containing tens of millions of vertices or more \cite{14Lee}.
When performing graph processing, the main operation is to obtain incident edges and neighboring vertices of a given vertex.
The way this action is performed depends on the internal representation of the graph in the computer's memory \cite{15Ahmed,16Salwasser}.
We will consider a representation of an undirected graph in which a list of neighboring vertices is available for each vertex index.
Let's consider the following graph decomposition algorithm -- the bubble growth algorithm -- which is one of the simplest in terms of work logic.

\begin{figure}[h]
\setcaptionmargin{5mm}
%\onelinecaptionsfalse % if the caption is multiline
\onelinecaptionstrue  % if the caption is one-line
\includegraphics[width=0.65\textwidth]{pics/incr.pdf}
\captionstyle{normal}\caption{Domain growth during the bubble decomposition algorithm.}\label{fig:incr}
\end{figure}

The bubble growth algorithm for graph decomposition \cite{17Fan} is based on a breadth-first traversal of the graph, performed simultaneously, starting from several initiating vertices.
At the beginning of the algorithm, the initiating vertices are randomly selected (according to the required number of domains).
Each of the selected vertices belongs to a corresponding domain.
After that, the process of simultaneous domain building begins, in which, at each iteration of the algorithm, one neighboring vertex that has not yet been colored is added to each domain (provided that this can be done).
The process ends when all the vertices of the graph are distributed across domains.
In Fig.~\ref{fig:incr} illustrates the process of building domains from randomly selected vertices for a graph on a plane.

After distributing all the vertices by domain, its center is calculated for each domain, after which the domain centers are taken as new initiating vertices, the graph coloring is reset, and then the domains are built from these new initiating vertices.
This process can continue either a fixed number of times, or until a certain condition is reached (stabilization of the initiating vertices, achieving a balanced partition, repeating the previously obtained configuration) \cite{18Golovchenko}.
The bubble growth algorithm does not guarantee a balanced division into domains or the formation of short boundaries between domains.
However, this algorithm is distinguished by its simplicity, which allows it to be used as a basic operation in complex approaches to the decomposition of \cite{19Wu}.

Let us briefly note the potential of using the bubble growth algorithm in the family of genetic algorithms \cite{20Katosh}.
Genetic algorithms are nature-like heuristic algorithms that are actively used to solve optimization problems with a large number of parameters \cite{21Wirayanti}.
During the operation of the genetic algorithm, the survival process of a population consisting of individual individuals is modeled, each of which represents a solution to some optimization problem.
To implement the algorithm, the concept of a genotype (some code of an individual) must be defined, the process of creating an individual based on its genotype must be implemented, the fitness function of the individual must be determined, and the operations of crossing and mutating individuals at the genotype level must be implemented.
In the process of population development, the weakest individuals die out, while the more fit ones leave offspring, which leads to an increase in the average value of the fitness function of individuals in the population.
Genetic algorithms are applicable for solving combinatorial optimization problems, in particular for graph decomposition problems.
However, when using a genetic algorithm to solve the graph decomposition problem, the concepts of genotype and individual are often mixed.
For example, in \cite{22Chaouche}, when decomposing a graph, each edge is encoded in the genotype, and in \cite{23Li}, the explicit distribution of vertices across domains is encoded in the genotype.
In other words, the genotype practically replaces the concept of an individual, which leads to a significant slowdown in the work of the genetic algorithm and the impossibility of its use for the decomposition of large graphs.
Also, the application of the mechanisms of crossing and mutation directly to individuals is questionable from the point of view of correctness.
The simplicity and speed of the bubble growth algorithm allows it to be used in genetic algorithms as an operation for constructing an individual from a genotype represented by a set of initiating vertices.
In this case, the shift of the initiating vertex to a random neighbor can be considered as a genotype mutation.
This approach of using the bubble growth algorithm inside the genetic algorithm has been approbated in practice, and the solution is available in an open repository https://github.com/r-aax/mendel.

\section{Векторизация алгоритма пузырькового роста}

Использование алгоритма пузырькового роста в качестве отдельной операции в комплексных подходах к декомпозиции графов предъявляет повышенные требования к его быстродействию.
Рассмотрим возможности по ускорению этого алгоритма с помощью векторизации.
Пусть мы имеем граф, информация о его ребрах записана в структуре \texttt{vector$<$vector$<$int$>>$ inc}, где \texttt{inc[i]} -- список номеров всех вершин, смежных с вершиной \texttt{i}.
Номера доменов, к которым относятся конкретные вершины хранятся в структуре \texttt{vector$<$int$>$ domains}.
Структура \texttt{vector$<$queue$<$int$>>$ q} -- список очередей вершин, ожидающих попадания в домены, в начале работы алгоритма очередь \texttt{q[i]} содержит только одну инициирующую вершину \texttt{i}-го домена.
Пусть требуется выполнить декомпозицию (или раскраску) на \texttt{domains\_count} доменов.
Тогда реализация алгоритма пузырькового роста доменов от инициирующих вершин может иметь следующий вид (см. листинг~\ref{lst:impl}):

\begin{lstlisting}[caption={Реализация алгоритма пузырькового роста доменов.},label={lst:impl}]
while (is_q)
{
    is_q = false;

    for (size_t c = 0; c < domains_count; ++c)
    {
        if (q[c].empty()) continue;

        is_q = true;
        n = q[c].front();
        q[c].pop();

        if (domains[n] == -1)
        {
            domains[n] = c;
            for (auto ngh : inc[n]) q[c].push(ngh);
        }
    }
}
\end{lstlisting}

Реализация алгоритма представляет собой гнездо из 3 циклов.
Внешний цикл выполняется до тех пор, пока найдется хотя бы одна непустая очередь домена (то есть остались нераспределенные по доменам вершины).
Средний цикл выполнятся по номерам доменов.
Для каждого домена берется первая необработанная вершина из соответствующей очереди, и если она еще не отнесена ни к одному домену, то она заносится в текущий домен, а все ее соседи отправляются в очередь.
Внутренний цикл -- цикл по всем соседям только что обработанной вершины, которые должны быть занесены в очередь.
Будем выполнять векторизацию представленного кода по среднему циклу, и для простоты анализа приведем реализацию для фиксированного значения \texttt{domains\_count = 16} (это позволит избавиться от среднего цикла, и заменить его набором отдельных векторных операций).

Для выполнения векторизации вначале необходимо избавиться от STL структур vector и queue, так как они имеют свою внутреннюю реализацию, и векторизация операций по работе с ними невозможна.
Вместо структуры \texttt{vector$<$int$>$} будем хранить информацию о списке соседних вершин просто в массиве, 0-м элементом которого будет его размер.
Очередь queue также будет имитировать с помощью массива и индексов \texttt{front} и \texttt{back}, указывающих на первый и последний элементы очереди соответственно.
Тогда операция \texttt{push(v)} будет соответствовать записи в массив по индексу \texttt{back} с его продвижением, а операция \texttt{pop} будет соответствовать просто продвижению индекса \texttt{front}.
Очередь пуста если ее индекс \texttt{front} больше индекса \texttt{back}.

\begin{figure}[h]
\setcaptionmargin{5mm}
\onelinecaptionsfalse % if the caption is multiline
%\onelinecaptionstrue  % if the caption is one-line
\includegraphics[width=0.85\textwidth]{pics/code.pdf}
\captionstyle{normal}\caption{Векторизация программного кода алгоритма пузырькового роста путем замены скалярных инструкций на векторные аналоги.}\label{fig:code}
\end{figure}

На рис.~\ref{fig:code} представлены скалярная и векторная версии программного кода реализации алгоритма пузырькового роста.
В векторной версии через \texttt{ADD}, \texttt{GTH}, \texttt{SCT} обозначаются функции-интринсики \texttt{\_mm512\_mask\_add\_epi32}, \texttt{\_mm512\_mask\_i32gather\_epi32}, \texttt{\_mm512\_i32scatter\_epi32} соответственно (\texttt{GTH2} и \texttt{SCT2} это те же операции \texttt{GTH} и \texttt{SCT}, только использующие сразу два смещения от базового адреса).
Через \texttt{CMPLE}, \texttt{CMPLT} обозначены вызовы функции-интринсика \texttt{\_mm512\_mask\_cmp\_epi32\_mask} с параметрами сравнения \texttt{\_MM\_CMPINT\_LE} и \texttt{\_MM\_CMPINT\_LT} соответственно.
На рис.~\ref{fig:code} цифрой <<1>> обозначена векторизация условия продолжения выполнения внешнего цикла (цикл завершает работу, если все очереди доменов пусты).
Цифрой <<2>> обозначена векторизация извлечения следующей вершины из каждой очереди.
Цифрой <<3>> обозначена проверка принадлежности извлеченных вершин к какому-либо домену (в векторной версии формируется маска \texttt{is\_no\_domain} -- маска с номерами доменов, в которые добавляется новая вершина).
Цифрой <<4>> обозначена векторизация помещения рассматриваемой вершины в текущий домен и получение количества ее соседей.
Цифра <<5>> -- обработка всех соседей только что помещенной в домен вершины, и цифра <<6>> -- добавление этих соседей в соответствующие очереди.

Стоит отметить, что векторизованная версия представленного алгоритма не является полностью эквивалентной скалярной версии.
Вполне может оказаться, что на какой-то итерации внешнего цикла из двух или более разных очередей одновременно будет извлечена одна и та же вершина.
В этом случае в векторной версии она будет отнесена к домену с наибольшим номером (хотя в скалярном аналоге, она бы попала в домен с меньшим номером).
Это несоответствие можно устранить путем разворачивания векторов \texttt{vn} и \texttt{vc} при записи в массив \texttt{domains} (цифра <<4>> на рис.~\ref{fig:code}), но это не делалось, чтобы не усложнять код.

\begin{figure}[h]
\setcaptionmargin{5mm}
\onelinecaptionsfalse % if the caption is multiline
%\onelinecaptionstrue  % if the caption is one-line
\begin{tabular}{ll}
\includegraphics[width=0.45\textwidth]{pics/chart_statistics_eng.png}
&
\includegraphics[width=0.45\textwidth]{pics/chart_speedup_eng.png}
\end{tabular}
\captionstyle{normal}\caption{Средняя плотность масок операций AVX-512 разных классов (слева) и ускорение вычислений, полученное на Intel Xeon Phi 7290 Knights Landing (справа).}\label{fig:chart}
\end{figure}

Для оценки эффективности проведенной векторизации были произведены запуски на дуальных графах поверхностных прямоугольных расчетных сеток со стороной от 20 до 2000 ячеек (то есть на графах с количеством вершин от 400 до 4 млн).
На рис.~\ref{fig:chart} слева представлена собранная статистика плотности масок (доля выставленных битов) векторных операций различных типов.
Из этих графиков можно сразу сделать вывод о невысокой эффективности векторизации, так как плотность масок арифметических операций и операций записи в память оказались довольно низкими (примерно 0,3 и 0,25 соответственно).

Замеры реального ускорения выполнялись для тех же графов на микропроцессоре Intel Xeon Phi 7290 Knights Landing, результаты представлены на рис.~\ref{fig:chart} справа, для удобства приведен также график сглаженного показателя ускорения.
Анализирую график сглаженного показателя ускорения, можно отметить, что максимум наблюдается при размере стороны расчетной сетки в районе 750 и равен примерно 1,95.
Снижение ускорения при уменьшении стороны расчетной сетки связано с увеличение количества конфликтов при обработке следующих вершин из очередей доменов.
Снижение ускорения при увеличении стороны расчетной сетки связано с увеличением разброса смещений при выполнении операций gather/scatter, что приводит к промахам в кэш-память.

\section{Conclusion}

В статье был рассмотрен алгоритм пузырькового роста, используемый для декомпозиции графа.
Этот алгоритм применяется для выполнения декомпозиции как в роли самостоятельного метода, так и в составе других, более комплексных подходов к декомпозиции.
Была рассмотрена реализация, в которой для каждого домена поддерживается своя очередь обрабатываемых вершин графа.
Такой подход допускает одновременную обработку очередей доменов, что делает возможным применение векторизации для ускорения вычислений.
Был предложен вариант векторизации алгоритма по среднему циклу гнезда для фиксированного количества доменов, равного 16.
Для полученного варианта векторизации была собрана статистика плотности векторных масок векторных операций в результирующем коде, которая показала крайне низкие значения для арифметических операций (около 0,3) и операций записи в память (около 0,25).
Такая низкая плотность масок связана с поведением внутреннего цикла, количество итераций которого можно охарактеризовать как нерегулярное, то есть никак не зависящее от номера итерации среднего цикла.
Замеры ускорения на микропроцессоре Intel Xeon Phi 7290 Knights Landing продемонстрировали ускорение в диапазоне 1,7-2,2 раза для рассматриваемых графов с количеством ячеек от 400 до 4 млн.
Такие невысокие результаты ускорения объясняются прежде всего нерегулярным количеством итераций циклов в гнезде, а также обилием операций множественного обращения в память gather/scatter.

\begin{acknowledgments}
Работа выполнена в рамках государственного задания НИЦ «Курчатовский институт».
\end{acknowledgments}

%
% The Bibliography
%

\begin{thebibliography}{99}

\bibitem{01Smirnov}
\refitem{article}
E.~M.~Smirnov, D.~K.~Zaitsev, A.~A.~Smirnovsky et al., \textquotedblleft Assessment of several advanced numerical algorithms implemented in the CFD code SINF/Flag-S for supercomputer simulations\textquotedblright, Supercomputing Frontiers and Innovations \textbf{11} (2), 14--31 (2024). https://doi.org/10.14529/jsfi240202

\bibitem{02Guo}
\refitem{article}
Z.~Guo, D.~Lu, Y.~Yan et al., \textquotedblleft Extending the limit of molecular dynamics with ab initio accuracy to 10 billion atoms\textquotedblright, 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, April 2--6, Seoul, Republic of Korea (2022). https://doi.org/10.1145/3503221.3508425

\bibitem{03Asch}
\refitem{article}
C.~Asch, E.~Francesquini, and E.~Meneses, \textquotedblleft An implementation of a plasma physiscs application for distributed-memory supercomputers using a directive-based programming framework\textquotedblright, Revista Colombiana de Computaci\'on \textbf{25} (1), 39--47 (2024). https://doi.org/10.29375/25392115.5053

\bibitem{04Morgan}
\refitem{article}
N.~Morgan, C.~Yanusah, A.~Diaz et al., \textquotedblleft Enabling parallel performance and portability of solid mechanics simulations across CPU and GPU architectures\textquotedblright, Information \textbf{15}, 716 (2024). https://doi.org/10.3390/info15110716

\bibitem{05Lohiya}
\refitem{article}
R.~Lohiya, and N.~Kumar, \textquotedblleft Harnessing the power of supercomputers: solving complex mathematical problems and queueing theory\textquotedblright, International Journal for Research Publication and Seminar \textbf{15} (1), 166--172. https://doi.org/10.36676/jrps.v15.il.1398

\bibitem{06Kang}
\refitem{article}
J.-S.~Kang, H.~Myung, and J.-H.~Yuk, \textquotedblleft Examination of computational performance and potential applications of a global numerical weather prediction model MPAS using KISTI supercomputer NURION\textquotedblright, Journal of Marine Science and Engineering \textbf{9}, 1147 (2021). https://doi.org/10.3390/jmse9101147

\bibitem{07Morad}
\refitem{article}
A.~Morad, \textquotedblleft Multidisciplinary conceptual investigation for integrating stores, not in the original configuration of a subsonic airplane\textquotedblright, Journal of Physics: Conference Series \textbf{2616}, 012005 (2023). https://doi.org/10.1088/1742-6596/2616/1/012005

\bibitem{08Eremin}
\refitem{article}
Н.~А.~Еремин, \textquotedblleft Эволюция цифровой нефтегазовой экосистемы от суперкомпьютинга к метакомпьютингу\textquotedblright, Известия Тульского государственного университета. Науки о Земле \textbf{1}, 190--201 (2023).

\bibitem{09Yan}
\refitem{article}
Y.-J.~Yan, H.-B.~Li, T.~Zhao et al., \textquotedblleft 10-million atoms simulation of first-principle package LS3DF\textquotedblright, Journal of Computer Science and Technology \textbf{39} (1), 45--62 (2024). https://doi.org/10.1007/s11390-023-3011-6

\bibitem{10Voevodin}
\refitem{article}
V.~V.~Voevodin, D.~I.~Shaikhislamov, and D.~A.~Nikitenko, \textquotedblleft How to assess the quality of supercomputer resource usage\textquotedblright, Supercomputing Frontiers and Innovations \textbf{9} (3), 4--18 (2022). https://doi.org/10.14529/jsfi220301

\bibitem{11Zhou}
\refitem{article}
Q.-W.~Zhou, J.-N.~Li, R.-C.~Zhao et al., \textquotedblleft Compilation optimization of DCU-oriented OpenMP thread scheduling\textquotedblright, Journal of Physics. Conference Series \textbf{2558} (1), 012003 (2023). https://doi.org/10.1088/1742-6596/2558/1/012003

\bibitem{12Feng}
\refitem{article}
J.~Feng, Y.~He, and Q.~Tao, \textquotedblleft Evaluation of compilers’ capability of automatic vectorization based on source code analysis\textquotedblright, Scientific Programming \textbf{6}, 1--15 (2021). https://doi.org/10.1155/2021/3264624

% --- AVX-512 examples

\bibitem{12-1Kulikov}
\refitem{article}
I.~Kulikov, I.~Chernykh, and A.~Tutukov, \textquotedblleft A new hydrodynamic code with explicit vectorization instructions optimizations that is dedicated to the numerical simulation of astrophysical gas flow. I. Numerical method, tests, and model problem\textquotedblright, The Astrophysical Journal Supplement Series \textbf{243} (4), 15~P. (2019). https://doi.org/10.3847/1538-4365/ab2237

\bibitem{12-2Buhrow}
\refitem{article}
B.~Buhrow, B.~Gilbert, and C.~Haider, \textquotedblleft Parallel modular multiplication using 512-bit advanced vector instructions\textquotedblright, Journal of Cryptographic Engineering, \textbf{12}, 95--105 (2022). https://doi.org/10.1007/s13389-021-00256-9

\bibitem{12-3Quislant}
\refitem{article}
R.~Quislant, and I.~Fernandez, \textquotedblleft Time series analysis acceleration with advanced vectorization extensions\textquotedblright, The Journal of Supercomputing, \textbf{79} (9), 10178--10207 (2023). https://doi.org/10.1007/s11227-023-05060-2

\bibitem{12-4Blacher}
\refitem{article}
M.~Blacher, J.~Giesen, P.~Sanders P. et al., \textquotedblleft Vectorized and performance-portable Quicksort\textquotedblright, arXiv, 2205.05982, 1--21 (2022). https://doi.org/10.48550/arXiv.2205.05982

\bibitem{12-5Sansone}
\refitem{article}
G.~Sansone, and M.~Cococcioni, \textquotedblleft Experiments on speeding up the recursive fast Fourier transform by using AVX-512 SIMD instructions\textquotedblright, In: R.~Berta, A.~De~Gloria (eds) Applications in Electronics Pervading Industry, Environment and Society, ApplePies 2022, Lecture Notes in Electrical Engineering \textbf{1036}. https://doi.org/10.1007/978-3-031-30333-3\_34

% ---

\bibitem{13Ayall}
\refitem{article}
T.~Ayall, H.~Liu, C.~Zhou et al., \textquotedblleft Graph computing systems and partitioning techniques: a survey\textquotedblright, IEEE Access \textbf{10}, 118523--118550 (2022). https://doi.org/10.1109/ACCESS.2022.3219422

\bibitem{14Lee}
\refitem{article}
H.~Lee, J.~Baek, S.~Song et al., \textquotedblleft Efficient large graph partitioning scheme using incremental processing in GPU\textquotedblright, IEEE Access \textbf{13}, 43889--43903 (2025). https://doi.org/10.1109/ACCESS.2025.3547976

\bibitem{15Ahmed}
\refitem{article}
A.~Ahmed, F.~Siddique, K.~Skadron et al., \textquotedblleft GraphTango: A hybrid representation format for efficient streaming graph updates and analysis\textquotedblright, International Journal of Parallel Programming \textbf{52}, 147--170 (2024). https://doi.org10.1007/s10766-024-00768-x

\bibitem{16Salwasser}
\refitem{article}
D.~Salwasser, D.~Seemaier, L.~Gottesb\"uren et al., \textquotedblleft Tera-scale multilevel graph partitioning\textquotedblright, arXiv 2410.19119 (2024). https://doi.org/10.48550/arXiv.2410.19119

\bibitem{17Fan}
\refitem{article}
W.~Fan, M.~Liu, C.~Tian et al., \textquotedblleft Incrementalization of graph partitioning algorithms\textquotedblright, Proceedings of the VLDB Endowment \textbf{13} (8), 1261--1274 (2020). https://doi.org/10.14778/3389133.3389142

\bibitem{18Golovchenko}
\refitem{article}
Е.~Н.~Головченко, \textquotedblleft Обзор алгоритмов декомпозиции графов\textquotedblright ,Препринты ИПМ им.~М.~В.~Келдыша \textbf{2} (2020). https://doi.org/10.20948/prepr-2020-2

\bibitem{19Wu}
\refitem{article}
Y.~Wu, J.~Du, and D.~Ni, \textquotedblleft Balanced domain partitioning for software defined networks\textquotedblright, IEEE Access \textbf{11}, 6467--6476 (2023). https://doi.org/10.1109/ACCESS.2023.3237733

\bibitem{20Katosh}
\refitem{article}
S.~Katosh, S.~Chauhan, and V.~Kumar, \textquotedblleft A review on genetic algorithm: past, present and future\textquotedblright, Multimedia Tools and Applications \textbf{80}, 8091--8126 (2020). https://doi.org/10.1007/s11042-020-10139-6

\bibitem{21Wirayanti}
\refitem{article}
N.~Wirayanti, and H.~Sriwindono, \textquotedblleft Implementation of hybrid genetic algorithm for solving the teacher placement problem\textquotedblright, Social Science and Humanities Journal. \textbf{9} (1), 6341--6347 (2025). https://doi.org/10.18535/sshj.v9i01.1460

\bibitem{22Chaouche}
\refitem{article}
A.~Chaouche, and M.~Boulif, \textquotedblleft Edge-set reduction to efficiently solve the graph partitioning problem with the genetic algorithm\textquotedblright, arXiv 2307.10410 (2023). https://doi.org/10.48550/arXiv.2307.10410

\bibitem{23Li}
\refitem{article}
M.~Li, H.~Cui, C.~Zhou et al., \textquotedblleft GAP: genetic algorithm based large-scale graph partition in heterogeneous cluster\textquotedblright, IEEE Access \textbf{8}, 144197--144204 (2020). https://doi.org/10.1109/ACCESS.2020.3014351

\end{thebibliography}
\end{document}
